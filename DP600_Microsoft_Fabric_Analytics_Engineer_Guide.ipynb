{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601e5259",
   "metadata": {},
   "source": [
    "# DP600: Microsoft Fabric Analytics Engineer Associate - Complete Learning Guide\n",
    "\n",
    "## Overview\n",
    "This notebook covers the Microsoft Fabric Analytics Engineer Associate (DP600) certification exam topics with core concepts, practical examples, tricks, and best practices.\n",
    "\n",
    "**Exam Details:**\n",
    "- Exam Code: DP600\n",
    "- Duration: 100 minutes\n",
    "- Questions: 40-60\n",
    "- Passing Score: 70%\n",
    "- Price: ~$99 USD\n",
    "- Difficulty: Intermediate-Advanced\n",
    "\n",
    "**Key Skills Measured:**\n",
    "- Fabric workspaces and analytics (25-30%)\n",
    "- Data warehouse (25-30%)\n",
    "- Lakehouse (20-25%)\n",
    "- Semantic models and reports (20-25%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5896e",
   "metadata": {},
   "source": [
    "# Part 1: Microsoft Fabric Fundamentals\n",
    "\n",
    "## 1.1 What is Microsoft Fabric?\n",
    "\n",
    "### Key Characteristics\n",
    "- **Unified Analytics Platform**: One integrated experience\n",
    "- **Cloud-native**: Built on Azure\n",
    "- **Managed Capacity**: Pay per capacity\n",
    "- **Notebook Support**: Interactive analysis\n",
    "- **Data Lake**: ADLS Gen2 integrated\n",
    "- **SQL**: Fully featured SQL engine\n",
    "- **Real-time Analytics**: Event streams\n",
    "\n",
    "### Fabric Workloads\n",
    "- **Data Factory**: Orchestration and ETL/ELT\n",
    "- **Synapse Data Warehouse**: OLAP analytics\n",
    "- **Synapse Data Science**: ML and data science\n",
    "- **Synapse Real-Time Analytics**: Streaming data\n",
    "- **Power BI**: Visualization and BI\n",
    "- **Lakehouse**: Data lake management\n",
    "\n",
    "### TRICK: Remember Fabric = Azure + Power BI unified\n",
    "- Single sign-on across all workloads\n",
    "- Shared capacity model\n",
    "- Integrated experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6681f",
   "metadata": {},
   "source": [
    "## 1.2 Fabric Capacity and Licensing\n",
    "\n",
    "### Capacity Tiers\n",
    "- **F64**: Entry level (Small)\n",
    "- **F128**: Standard\n",
    "- **F256**: Large\n",
    "- **F512**: Enterprise\n",
    "- **F1024**: Ultra\n",
    "- **F2048**: Maximum\n",
    "\n",
    "### Billing Model\n",
    "- **Capacity Unit (CU)**: Base measurement\n",
    "- **Monthly subscription**: Fixed cost\n",
    "- **Pay-as-you-go**: Variable option\n",
    "- **Shared capacity**: Premium Per User licensing\n",
    "\n",
    "### User Licenses\n",
    "- **Power BI Premium**: Required for Fabric features\n",
    "- **Viewer/Contributor**: Per-user licensing\n",
    "- **Premium Per User**: Shared capacity option\n",
    "\n",
    "### Cost Optimization\n",
    "- Pause capacity during off-hours\n",
    "- Right-size capacity\n",
    "- Monitor utilization\n",
    "- Use shared capacity for dev/test\n",
    "\n",
    "### TRICK: Capacity planning\n",
    "- Start with F64, scale up as needed\n",
    "- 1 CU â‰ˆ 1 hour of compute\n",
    "- Monitor Fabric Capacity Metrics app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577984d",
   "metadata": {},
   "source": [
    "## 1.3 Fabric Workspaces\n",
    "\n",
    "### Workspace Fundamentals\n",
    "- **Container**: Holds all Fabric items\n",
    "- **Collaboration**: Team-based access\n",
    "- **Permissions**: Role-based access\n",
    "- **OneLake**: Unified data lake\n",
    "\n",
    "### Workspace Roles\n",
    "1. **Admin**: Full control\n",
    "2. **Member**: Create and edit\n",
    "3. **Contributor**: Can create items\n",
    "4. **Viewer**: Read-only access\n",
    "\n",
    "### Workspace Storage\n",
    "- Automatic OneLake storage\n",
    "- ADLS Gen2 backend\n",
    "- File structure preserved\n",
    "- No additional cost for storage\n",
    "\n",
    "### Items in Workspace\n",
    "- Data Warehouse\n",
    "- Lakehouse\n",
    "- Semantic Model\n",
    "- Report\n",
    "- Notebook\n",
    "- Pipeline\n",
    "- Dataflow\n",
    "- KQL Queryset\n",
    "\n",
    "### TRICK: Workspace organization\n",
    "- Dev/Test/Prod workspaces for environment separation\n",
    "- One workspace per project recommended\n",
    "- Use workspace roles for governance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a4405",
   "metadata": {},
   "source": [
    "# Part 2: Data Warehouse in Fabric\n",
    "\n",
    "## 2.1 Fabric Data Warehouse Basics\n",
    "\n",
    "### Key Features\n",
    "- **OLAP Engine**: Optimized analytics\n",
    "- **T-SQL Support**: Transact-SQL compatibility\n",
    "- **Columnar Storage**: Efficient compression\n",
    "- **Auto-scale**: Dynamic resource allocation\n",
    "- **OneLake Integration**: Built-in data lake\n",
    "\n",
    "### Data Warehouse vs SQL Database\n",
    "| Feature | Data Warehouse | SQL Database |\n",
    "|---------|----------------|---------------|\n",
    "| Purpose | Analytics | Transactions |\n",
    "| Storage | Columnar | Row-based |\n",
    "| Scale | Massive | Medium |\n",
    "| Query Type | Complex | Simple |\n",
    "| Cost | Higher (large data) | Lower (small) |\n",
    "\n",
    "### Tables in Data Warehouse\n",
    "- **Fact Tables**: Transactional measures\n",
    "- **Dimension Tables**: Descriptive attributes\n",
    "- **Staging Tables**: Temporary loading\n",
    "\n",
    "### TRICK: Warehouse design\n",
    "- Star schema: Fact with dimensions\n",
    "- Snowflake schema: Normalized dimensions\n",
    "- Data vault: Complex relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462f2b6",
   "metadata": {},
   "source": [
    "## 2.2 Data Warehouse SQL Operations\n",
    "\n",
    "### Creating Tables\n",
    "```sql\n",
    "-- Fact Table\n",
    "CREATE TABLE fact_sales (\n",
    "    sale_id INT,\n",
    "    product_id INT,\n",
    "    customer_id INT,\n",
    "    amount DECIMAL(10, 2),\n",
    "    sale_date DATE,\n",
    "    PRIMARY KEY (sale_id)\n",
    ");\n",
    "\n",
    "-- Dimension Table\n",
    "CREATE TABLE dim_product (\n",
    "    product_id INT PRIMARY KEY,\n",
    "    product_name VARCHAR(100),\n",
    "    category VARCHAR(50)\n",
    ");\n",
    "```\n",
    "\n",
    "### Indexing Strategies\n",
    "- **Clustered Index**: Primary sort order\n",
    "- **Heap**: No clustered index\n",
    "- **Columnstore**: Compressed analytics\n",
    "\n",
    "### Performance Optimization\n",
    "```sql\n",
    "-- Partition table for performance\n",
    "CREATE TABLE sales_partitioned (\n",
    "    sale_id INT,\n",
    "    amount DECIMAL(10, 2),\n",
    "    sale_year INT\n",
    ")\n",
    "WITH (DISTRIBUTION = HASH(sale_id))\n",
    "PARTITION BY (sale_year);\n",
    "\n",
    "-- Create statistics\n",
    "CREATE STATISTICS stat_product ON fact_sales(product_id);\n",
    "```\n",
    "\n",
    "### TRICK: Query optimization\n",
    "- Use WHERE clause early\n",
    "- Join on distribution columns\n",
    "- Create statistics on join columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350df6",
   "metadata": {},
   "source": [
    "## 2.3 Data Loading into Warehouse\n",
    "\n",
    "### COPY Statement (Fastest)\n",
    "```sql\n",
    "COPY INTO fact_sales\n",
    "FROM 'https://account.blob.core.windows.net/container/sales.csv'\n",
    "WITH (\n",
    "    FILE_TYPE = 'CSV',\n",
    "    CREDENTIAL = (IDENTITY = 'Shared Access Signature', SECRET = 'token'),\n",
    "    FIELDTERMINATOR = ',',\n",
    "    ROWTERMINATOR = '0x0a'\n",
    ");\n",
    "```\n",
    "\n",
    "### INSERT INTO SELECT\n",
    "```sql\n",
    "INSERT INTO fact_sales\n",
    "SELECT sale_id, product_id, customer_id, amount, sale_date\n",
    "FROM staging_sales;\n",
    "```\n",
    "\n",
    "### Loading Patterns\n",
    "- **Full Load**: Initial data load\n",
    "- **Incremental**: New records only\n",
    "- **Upsert**: Insert or update\n",
    "- **Slowly Changing Dimension (SCD)**: Type 1, 2, 3\n",
    "\n",
    "### TRICK: Optimize loading\n",
    "- COPY statement is 2-3x faster\n",
    "- Bulk insert for large files\n",
    "- Disable indexes during load\n",
    "- Use staging tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc718a",
   "metadata": {},
   "source": [
    "# Part 3: Lakehouse in Fabric\n",
    "\n",
    "## 3.1 Lakehouse Fundamentals\n",
    "\n",
    "### What is a Lakehouse?\n",
    "- **Hybrid**: Lake + Warehouse benefits\n",
    "- **Schema-on-read**: Flexible schema\n",
    "- **Delta Tables**: ACID transactions\n",
    "- **Metadata**: Automatic indexing\n",
    "- **Unstructured + Structured**: Both supported\n",
    "\n",
    "### Lakehouse Components\n",
    "1. **Files**: Raw data storage\n",
    "2. **Shortcuts**: External data references\n",
    "3. **Tables**: Governed data objects\n",
    "4. **Notebooks**: Interactive analysis\n",
    "\n",
    "### Delta Format\n",
    "- **ACID Transactions**: Reliable updates\n",
    "- **Schema Evolution**: Add columns\n",
    "- **Time Travel**: Query historical\n",
    "- **Data Lineage**: Track changes\n",
    "\n",
    "### Lakehouse vs Data Warehouse\n",
    "| Aspect | Lakehouse | Warehouse |\n",
    "|--------|-----------|----------|\n",
    "| Schema | Flexible | Fixed |\n",
    "| Data | All types | Structured |\n",
    "| Query | Spark/SQL | SQL |\n",
    "| Cost | Lower | Higher |\n",
    "| Analytics | ML friendly | BI friendly |\n",
    "\n",
    "### TRICK: When to use what\n",
    "- Raw data ingestion â†’ Lakehouse\n",
    "- SQL analytics â†’ Data Warehouse\n",
    "- ML pipelines â†’ Lakehouse\n",
    "- BI reports â†’ Warehouse tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae602a",
   "metadata": {},
   "source": [
    "## 3.2 Working with Lakehouse Tables\n",
    "\n",
    "### Creating Tables from DataFrame\n",
    "```python\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.read.csv(\"/lakehouse/files/data.csv\", header=True)\n",
    "\n",
    "# Save as Delta table\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"sales\")\n",
    "\n",
    "# Or save to lakehouse\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/lakehouse/tables/sales\")\n",
    "```\n",
    "\n",
    "### Reading Data\n",
    "```python\n",
    "# Read from lakehouse table\n",
    "df = spark.read.table(\"sales\")\n",
    "\n",
    "# Read from files\n",
    "df = spark.read.format(\"delta\").load(\"/lakehouse/tables/sales\")\n",
    "\n",
    "# Read CSV\n",
    "df = spark.read.csv(\"/lakehouse/files/data.csv\", header=True)\n",
    "```\n",
    "\n",
    "### Delta Operations\n",
    "```python\n",
    "# Update records\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE sales\n",
    "    SET amount = amount * 1.1\n",
    "    WHERE year = 2024\n",
    "\"\"\")\n",
    "\n",
    "# Delete records\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM sales\n",
    "    WHERE customer_id = 'INVALID'\n",
    "\"\"\")\n",
    "\n",
    "# Merge (Upsert)\n",
    "spark.sql(\"\"\"\n",
    "    MERGE INTO sales t\n",
    "    USING staging s\n",
    "    ON t.sale_id = s.sale_id\n",
    "    WHEN MATCHED THEN UPDATE SET t.amount = s.amount\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "### TRICK: Lakehouse best practices\n",
    "- Use Delta format for tables\n",
    "- Organize files by date/source\n",
    "- Use partitioning for large tables\n",
    "- Enable z-ordering for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8558a1",
   "metadata": {},
   "source": [
    "## 3.3 Shortcuts in Lakehouse\n",
    "\n",
    "### What are Shortcuts?\n",
    "- Reference external data without copying\n",
    "- Reduced storage costs\n",
    "- Data stays in original location\n",
    "- ADLS Gen2 or Azure Blob Storage\n",
    "\n",
    "### Types of Shortcuts\n",
    "1. **ADLS Gen2 Shortcut**: On-premises or cloud\n",
    "2. **Warehouse Shortcut**: Link to another warehouse\n",
    "3. **OneLake Shortcut**: Another Fabric workspace\n",
    "\n",
    "### Creating Shortcuts\n",
    "```\n",
    "UI: New â†’ Shortcut\n",
    "â”œâ”€ Azure Blob Storage\n",
    "â”œâ”€ ADLS Gen2\n",
    "â”œâ”€ Warehouse\n",
    "â””â”€ OneLake\n",
    "```\n",
    "\n",
    "### TRICK: Shortcut strategies\n",
    "- Reference source systems directly\n",
    "- Link dependent workspaces\n",
    "- Avoid data duplication\n",
    "- Monitor access patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63191402",
   "metadata": {},
   "source": [
    "# Part 4: Data Integration with Pipelines\n",
    "\n",
    "## 4.1 Fabric Pipelines\n",
    "\n",
    "### Pipeline Fundamentals\n",
    "- **Orchestration**: Workflow automation\n",
    "- **Activities**: Individual tasks\n",
    "- **Scheduling**: Time-based or event-based\n",
    "- **Monitoring**: Track runs and failures\n",
    "\n",
    "### Pipeline Activities\n",
    "1. **Copy Data**: Move between sources/destinations\n",
    "2. **Notebook**: Execute Spark code\n",
    "3. **SQL Query**: Run T-SQL\n",
    "4. **Stored Procedure**: Execute SQL procedures\n",
    "5. **Delete Data**: Remove rows\n",
    "6. **Web Activity**: Call HTTP endpoints\n",
    "7. **Lookup**: Retrieve metadata\n",
    "8. **Control Flow**: If/Loop/Wait\n",
    "\n",
    "### Copy Activity Optimization\n",
    "- **Parallel Copies**: Default 4, max 256\n",
    "- **Staging**: For complex scenarios\n",
    "- **Compression**: Reduce data transfer\n",
    "- **Batch Size**: Tune for performance\n",
    "\n",
    "### TRICK: Pipeline design\n",
    "- Use variables for flexibility\n",
    "- Add error handling\n",
    "- Monitor resource utilization\n",
    "- Test with sample data first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17238b",
   "metadata": {},
   "source": [
    "## 4.2 Dataflows and Data Loading\n",
    "\n",
    "### Dataflow (Gen2)\n",
    "- **Visual ETL**: Graphical transformation\n",
    "- **Power Query**: Familiar transformation engine\n",
    "- **No-code**: Non-technical users\n",
    "- **Scheduled**: Automation support\n",
    "\n",
    "### Dataflow Transformations\n",
    "- **Source**: Read data\n",
    "- **Filter**: Row filtering\n",
    "- **Select**: Column selection\n",
    "- **Group By**: Aggregation\n",
    "- **Merge Queries**: Join/combine\n",
    "- **Append Queries**: Union\n",
    "- **Add Column**: Custom column\n",
    "- **Unpivot**: Reshape data\n",
    "\n",
    "### Incremental Loading with Dataflow\n",
    "```\n",
    "1. Add watermark column\n",
    "2. Store max watermark in metadata\n",
    "3. Filter by watermark > last_run\n",
    "4. Load only new data\n",
    "```\n",
    "\n",
    "### TRICK: Dataflow optimization\n",
    "- Remove unnecessary columns early\n",
    "- Filter before transformations\n",
    "- Use native queries when possible\n",
    "- Schedule during off-peak hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57468c",
   "metadata": {},
   "source": [
    "# Part 5: Semantic Models and Relationships\n",
    "\n",
    "## 5.1 Semantic Model (formerly Dataset) Fundamentals\n",
    "\n",
    "### What is a Semantic Model?\n",
    "- **Business Logic**: Calculations and rules\n",
    "- **Data Model**: Tables and relationships\n",
    "- **Metadata**: Descriptions and hierarchies\n",
    "- **Reusable**: Share across reports\n",
    "\n",
    "### Model Types\n",
    "1. **Import**: Data loaded to memory\n",
    "   - Best performance\n",
    "   - Limited by memory\n",
    "   - Scheduled refresh needed\n",
    "\n",
    "2. **DirectQuery**: Real-time source\n",
    "   - Always current\n",
    "   - Slower performance\n",
    "   - Direct database load\n",
    "\n",
    "3. **Live Connection**: Connect to Analysis Services\n",
    "   - Real-time data\n",
    "   - Shared model\n",
    "   - One semantic model per report\n",
    "\n",
    "4. **Composite**: Mix of Import/DirectQuery\n",
    "   - Flexible\n",
    "   - Complex configuration\n",
    "\n",
    "### Model Optimization\n",
    "- Reduce cardinality\n",
    "- Summarize large tables\n",
    "- Hide unnecessary columns\n",
    "- Use calculation groups\n",
    "\n",
    "### TRICK: Model selection\n",
    "- < 1 GB data â†’ Import\n",
    "- Need real-time â†’ DirectQuery\n",
    "- Some real-time â†’ Composite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a615c75",
   "metadata": {},
   "source": [
    "## 5.2 Relationships and Star Schema\n",
    "\n",
    "### Relationship Types\n",
    "1. **One-to-Many**: Dimension to Fact\n",
    "   - Most common\n",
    "   - One product â†’ Many sales\n",
    "\n",
    "2. **Many-to-Many**: Complex relationships\n",
    "   - Use with caution\n",
    "   - Can impact performance\n",
    "\n",
    "3. **One-to-One**: Same information level\n",
    "   - Rare in analytics\n",
    "\n",
    "### Star Schema Design\n",
    "```\n",
    "        DIM_DATE\n",
    "           |\n",
    "        FACT_SALES\n",
    "        /    |    \\\n",
    "    DIM_PRODUCT  DIM_CUSTOMER  DIM_REGION\n",
    "```\n",
    "\n",
    "### Relationship Properties\n",
    "- **Cardinality**: 1:1, 1:*, *:1, *:*\n",
    "- **Direction**: Single or both\n",
    "- **Active**: Only one active relationship\n",
    "- **Security**: Use for RLS\n",
    "\n",
    "### DAX Relationships\n",
    "```\n",
    "RELATED() - Get related row value\n",
    "RELATEDTABLE() - Get related table\n",
    "CROSSFILTER() - Set filter direction\n",
    "```\n",
    "\n",
    "### TRICK: Relationship design\n",
    "- One-to-many: Dimension to Fact\n",
    "- Join on unique key\n",
    "- Maintain referential integrity\n",
    "- Document complex relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51e1d0",
   "metadata": {},
   "source": [
    "## 5.3 Measures and Calculations\n",
    "\n",
    "### DAX (Data Analysis Expressions)\n",
    "```\n",
    "// Implicit Measure\n",
    "Total Sales = SUM(Sales[Amount])\n",
    "\n",
    "// Explicit Measure\n",
    "Avg Price = AVERAGEX(Products, Products[Price])\n",
    "\n",
    "// Conditional\n",
    "Profit = \n",
    "IF(\n",
    "    [Revenue] > [Cost],\n",
    "    [Revenue] - [Cost],\n",
    "    0\n",
    ")\n",
    "\n",
    "// Time Intelligence\n",
    "YTD Sales = TOTALYTD(SUM(Sales[Amount]), 'Date'[Date])\n",
    "```\n",
    "\n",
    "### Measure Types\n",
    "- **Simple**: SUM, COUNT, AVERAGE\n",
    "- **Calculated**: Complex expressions\n",
    "- **Quick**: Temporary calculations\n",
    "- **Calculation Groups**: Reusable logic\n",
    "\n",
    "### Performance Optimization\n",
    "- Use summarized tables\n",
    "- Reduce formula complexity\n",
    "- Use calculation groups\n",
    "- Cache frequently used measures\n",
    "\n",
    "### TRICK: DAX best practices\n",
    "- Use CALCULATE for context\n",
    "- Avoid row-by-row evaluation\n",
    "- Test performance\n",
    "- Use EXPLAIN to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a0d48",
   "metadata": {},
   "source": [
    "# Part 6: Power BI Reports in Fabric\n",
    "\n",
    "## 6.1 Report Design and Formatting\n",
    "\n",
    "### Report Pages\n",
    "- Multiple pages for organization\n",
    "- Navigation buttons\n",
    "- Bookmarks for states\n",
    "- Mobile layout\n",
    "\n",
    "### Visualization Types\n",
    "| Visual | Use Case |\n",
    "|--------|----------|\n",
    "| Table | Detail data |\n",
    "| Matrix | Multi-dimensional |\n",
    "| Bar | Category comparison |\n",
    "| Line | Trends |\n",
    "| Scatter | Correlation |\n",
    "| Map | Geographic |\n",
    "| Pie | Proportions |\n",
    "| Key Performance Indicator (KPI) | Metrics |\n",
    "\n",
    "### Interactivity\n",
    "- **Slicers**: Filter controls\n",
    "- **Drill-down**: Hierarchical navigation\n",
    "- **Cross-filtering**: Visual interaction\n",
    "- **Tooltips**: Hover information\n",
    "\n",
    "### Design Best Practices\n",
    "1. Clear title and labels\n",
    "2. Consistent color scheme\n",
    "3. Remove clutter\n",
    "4. Logical layout\n",
    "5. Accessibility (color-blind)\n",
    "6. Mobile optimization\n",
    "\n",
    "### TRICK: Report optimization\n",
    "- Limit visuals per page\n",
    "- Use slicers for filtering\n",
    "- Hide unnecessary fields\n",
    "- Test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ff39f",
   "metadata": {},
   "source": [
    "## 6.2 Report Interactivity and Navigation\n",
    "\n",
    "### Navigation Techniques\n",
    "1. **Page Navigation**: Multiple report pages\n",
    "2. **Drill-through**: Navigate to detail pages\n",
    "3. **Bookmarks**: Save specific states\n",
    "4. **Buttons**: Navigate between pages\n",
    "5. **Drilldown**: Expand hierarchies\n",
    "\n",
    "### Drill-through Setup\n",
    "```\n",
    "1. Add drill-through fields to target page\n",
    "2. Add context filter fields\n",
    "3. Set up button or click behavior\n",
    "4. Configure drill-through parameters\n",
    "```\n",
    "\n",
    "### Bookmarks\n",
    "- Save current state\n",
    "- Reset filters\n",
    "- Show/hide visuals\n",
    "- Button navigation\n",
    "\n",
    "### Parameters (New)\n",
    "- Dynamic filtering\n",
    "- What-if analysis\n",
    "- User input values\n",
    "\n",
    "### TRICK: Create user experience\n",
    "- Breadcrumb navigation\n",
    "- Clear action buttons\n",
    "- Consistent interaction patterns\n",
    "- Save report state in bookmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda96585",
   "metadata": {},
   "source": [
    "# Part 7: Real-Time Analytics in Fabric\n",
    "\n",
    "## 7.1 Real-Time Analytics Components\n",
    "\n",
    "### Kusto Query Language (KQL)\n",
    "- **Purpose**: Time-series data analysis\n",
    "- **Speed**: Sub-second queries\n",
    "- **Scalability**: Massive datasets\n",
    "- **Format**: Optimized for analytics\n",
    "\n",
    "### Event Streams\n",
    "- **Purpose**: Ingest real-time data\n",
    "- **Sources**: Azure Event Hubs, Kafka\n",
    "- **Processing**: Real-time transformation\n",
    "- **Destinations**: Multiple targets\n",
    "\n",
    "### KQL Database vs Data Warehouse\n",
    "| Aspect | KQL DB | Warehouse |\n",
    "|--------|--------|----------|\n",
    "| Data Type | Time-series | Relational |\n",
    "| Query Speed | Sub-second | Seconds |\n",
    "| Scale | PB | TB-PB |\n",
    "| Latency | Low | Medium |\n",
    "| Query Language | KQL | T-SQL |\n",
    "\n",
    "### TRICK: Real-time scenarios\n",
    "- IOT sensors â†’ Event Streams + KQL\n",
    "- Application logs â†’ Event Hubs + KQL\n",
    "- Customer activity â†’ Event Streams + Power BI\n",
    "- Fraud detection â†’ KQL real-time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac87a5f",
   "metadata": {},
   "source": [
    "## 7.2 KQL Query Basics\n",
    "\n",
    "### KQL Query Structure\n",
    "```kusto\n",
    "// Basic query\n",
    "log_data\n",
    "| where timestamp >= ago(1d)\n",
    "| summarize Count=count() by source\n",
    "| sort by Count desc\n",
    "\n",
    "// Join tables\n",
    "log_data\n",
    "| join kind=inner (\n",
    "    error_log\n",
    ") on request_id\n",
    "\n",
    "// Time-based aggregation\n",
    "events\n",
    "| where timestamp >= ago(24h)\n",
    "| summarize Events=count() by bin(timestamp, 5m), event_type\n",
    "```\n",
    "\n",
    "### Common KQL Operations\n",
    "- **where**: Filter rows\n",
    "- **summarize**: Aggregate data\n",
    "- **project**: Select columns\n",
    "- **sort**: Order results\n",
    "- **join**: Combine tables\n",
    "- **union**: Combine rows\n",
    "- **extend**: Add calculated columns\n",
    "\n",
    "### Time Functions\n",
    "- `now()`: Current time\n",
    "- `ago(1d)`: 1 day ago\n",
    "- `bin(timestamp, 5m)`: 5-minute buckets\n",
    "\n",
    "### TRICK: KQL optimization\n",
    "- Filter early with where\n",
    "- Project only needed columns\n",
    "- Use bin() for time aggregation\n",
    "- Leverage pre-aggregated tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3c240",
   "metadata": {},
   "source": [
    "# Part 8: Notebooks and Data Science\n",
    "\n",
    "## 8.1 Spark Notebooks in Fabric\n",
    "\n",
    "### Notebook Cells\n",
    "- **Code**: Python, Scala, SQL, R\n",
    "- **Markdown**: Documentation\n",
    "- **Execute**: Run cells individually or all\n",
    "- **Output**: Display results inline\n",
    "\n",
    "### Reading/Writing Data\n",
    "```python\n",
    "# Read from lakehouse\n",
    "df = spark.read.table(\"sales\")\n",
    "\n",
    "# Read CSV\n",
    "df = spark.read.csv(\"/path/to/file.csv\", header=True)\n",
    "\n",
    "# Write to lakehouse\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"processed_sales\")\n",
    "\n",
    "# Read from warehouse\n",
    "df = spark.read.format(\"com.microsoft.kusto.spark.synapse.ml\") \\\n",
    "    .option(\"kustoCluster\", \"cluster_url\") \\\n",
    "    .option(\"kustoDatabase\", \"db_name\") \\\n",
    "    .load()\n",
    "```\n",
    "\n",
    "### Spark DataFrames\n",
    "```python\n",
    "# Transformations\n",
    "df_filtered = df.filter(df.amount > 100)\n",
    "df_grouped = df.groupby('category').sum('amount')\n",
    "df_joined = df1.join(df2, 'id')\n",
    "\n",
    "# Display\n",
    "display(df)\n",
    "df.show()\n",
    "\n",
    "# Statistics\n",
    "df.describe().show()\n",
    "df.printSchema()\n",
    "```\n",
    "\n",
    "### TRICK: Notebook best practices\n",
    "- Document with markdown\n",
    "- Test cells incrementally\n",
    "- Use variables for reusability\n",
    "- Save outputs to tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5423da",
   "metadata": {},
   "source": [
    "## 8.2 Machine Learning in Fabric\n",
    "\n",
    "### ML Libraries\n",
    "- **PySpark ML**: Distributed ML\n",
    "- **scikit-learn**: Single-node ML\n",
    "- **TensorFlow**: Deep learning\n",
    "- **XGBoost**: Gradient boosting\n",
    "- **MLflow**: Model tracking\n",
    "\n",
    "### ML Pipeline Example\n",
    "```python\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Feature engineering\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"category_idx\")\n",
    "assembler = VectorAssembler(inputCols=[\"category_idx\", \"price\"], outputCol=\"features\")\n",
    "\n",
    "# Model\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol=\"target\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler, model])\n",
    "fitted_model = pipeline.fit(df_train)\n",
    "\n",
    "# Predict\n",
    "predictions = fitted_model.transform(df_test)\n",
    "```\n",
    "\n",
    "### Model Deployment\n",
    "- Train in notebook\n",
    "- Save to MLflow\n",
    "- Register model\n",
    "- Deploy to Power BI\n",
    "\n",
    "### TRICK: ML in Fabric\n",
    "- Start with simple models\n",
    "- Use cross-validation\n",
    "- Track experiments with MLflow\n",
    "- Monitor model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e3f83",
   "metadata": {},
   "source": [
    "# Part 9: Governance and Security\n",
    "\n",
    "## 9.1 Fabric Security Features\n",
    "\n",
    "### Authentication\n",
    "- **Azure AD**: Primary identity\n",
    "- **Service Principal**: App access\n",
    "- **Managed Identity**: Fabric services\n",
    "- **MFA**: Multi-factor authentication\n",
    "\n",
    "### Authorization\n",
    "- **Workspace Roles**: Admin, Member, Contributor, Viewer\n",
    "- **Item Permissions**: Item-level access\n",
    "- **Row-Level Security (RLS)**: Data filtering\n",
    "- **Column-Level Security**: Column masking\n",
    "\n",
    "### Encryption\n",
    "- **At Rest**: Automatic with Microsoft keys\n",
    "- **In Transit**: HTTPS/TLS\n",
    "- **Bring Your Own Key (BYOK)**: Customer-managed\n",
    "\n",
    "### Data Sensitivity Labels\n",
    "- Mark sensitive data\n",
    "- Automatic policies\n",
    "- Export protection\n",
    "\n",
    "### TRICK: Security layering\n",
    "- Authentication â†’ Authorization â†’ Encryption\n",
    "- Use RLS for multi-tenant\n",
    "- Apply labels to sensitive data\n",
    "- Regular access reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed36bee",
   "metadata": {},
   "source": [
    "## 9.2 Governance and Monitoring\n",
    "\n",
    "### Workspace Governance\n",
    "- **Capacity**: Monitor utilization\n",
    "- **Premium Features**: Enable/disable\n",
    "- **Endorsement**: Promote content\n",
    "- **Lineage**: Track data flow\n",
    "\n",
    "### Audit and Monitoring\n",
    "- **Activity Log**: Track user actions\n",
    "- **Alerts**: Automatic notifications\n",
    "- **Metrics**: Performance tracking\n",
    "- **Workload**: Resource allocation\n",
    "\n",
    "### Data Lineage\n",
    "- Visualize data flow\n",
    "- Impact analysis\n",
    "- Change tracking\n",
    "- Compliance audit\n",
    "\n",
    "### Fabric Capacity Metrics\n",
    "- Real-time monitoring\n",
    "- CPU and memory usage\n",
    "- Query performance\n",
    "- Cost analysis\n",
    "\n",
    "### TRICK: Governance best practices\n",
    "- Monitor capacity utilization daily\n",
    "- Set up alerts for issues\n",
    "- Track data lineage\n",
    "- Regular audit reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5282c8",
   "metadata": {},
   "source": [
    "# Part 10: Exam Tips and Practice\n",
    "\n",
    "## 10.1 Key Concepts Summary\n",
    "\n",
    "### Fabric Architecture\n",
    "- Workspace: Container for all items\n",
    "- OneLake: Unified data lake\n",
    "- Capacity: Compute resources\n",
    "- Workloads: Data Factory, Warehouse, Lakehouse, Real-time, Power BI\n",
    "\n",
    "### Storage Options\n",
    "- Data Warehouse: OLAP, T-SQL, Columnar\n",
    "- Lakehouse: ACID Delta, Unstructured, Spark/SQL\n",
    "- KQL Database: Time-series, Real-time, KQL\n",
    "\n",
    "### Data Loading\n",
    "- Pipelines: Complex orchestration\n",
    "- Dataflows: Visual ETL\n",
    "- Notebooks: Programmatic (Python, Scala)\n",
    "- Copy Activity: Direct transfer\n",
    "\n",
    "### Semantic Modeling\n",
    "- Import: Best performance\n",
    "- DirectQuery: Real-time\n",
    "- Composite: Flexible\n",
    "- Star Schema: Dimension + Fact\n",
    "\n",
    "## 10.2 Common Exam Patterns\n",
    "\n",
    "### When you see \"Historical analytics\"...\n",
    "- Data Warehouse\n",
    "- Import model\n",
    "- Star schema\n",
    "\n",
    "### When you see \"ML pipeline\"...\n",
    "- Lakehouse\n",
    "- Spark notebook\n",
    "- Delta tables\n",
    "\n",
    "### When you see \"Real-time\"...\n",
    "- KQL Database\n",
    "- Event Streams\n",
    "- Real-time Analytics\n",
    "\n",
    "### When you see \"Flexible schema\"...\n",
    "- Lakehouse\n",
    "- Files folder\n",
    "- Notebook\n",
    "\n",
    "### When you see \"BI reporting\"...\n",
    "- Semantic Model\n",
    "- Power BI report\n",
    "- Import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a390c2",
   "metadata": {},
   "source": [
    "## 10.3 Practice Questions\n",
    "\n",
    "## Question 1: Storage Selection\n",
    "**Scenario**: Need to store raw data with unstructured files and run ML models. What to use?\n",
    "\n",
    "A) Data Warehouse\n",
    "B) Lakehouse\n",
    "C) KQL Database\n",
    "D) Warehouse + separate storage\n",
    "\n",
    "**Answer**: B (Lakehouse)\n",
    "**Explanation**: Lakehouse supports both structured and unstructured data, plus Spark for ML.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2: Model Refresh Strategy\n",
    "**Scenario**: Need real-time data for report. Daily refresh at 8 AM too slow. What model?\n",
    "\n",
    "A) Import model\n",
    "B) DirectQuery\n",
    "C) Live connection\n",
    "D) Refresh every hour\n",
    "\n",
    "**Answer**: B (DirectQuery)\n",
    "**Explanation**: DirectQuery always queries source, no refresh needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3: Pipeline vs Dataflow\n",
    "**Scenario**: Complex ETL with multiple transformations and error handling. What tool?\n",
    "\n",
    "A) Dataflow\n",
    "B) Pipeline\n",
    "C) Notebook\n",
    "D) COPY statement\n",
    "\n",
    "**Answer**: B (Pipeline)\n",
    "**Explanation**: Pipelines offer better error handling and control flow.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4: Lakehouse Optimization\n",
    "**Scenario**: Large sales table (10GB) with slow queries. How to optimize?\n",
    "\n",
    "A) Increase capacity\n",
    "B) Use DirectQuery\n",
    "C) Partition table by date, enable z-ordering\n",
    "D) Create warehouse copy\n",
    "\n",
    "**Answer**: C (Partition + Z-order)\n",
    "**Explanation**: Delta optimization improves query performance for large tables.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 5: KQL Use Case\n",
    "**Scenario**: Need to analyze IOT sensor data with millions of events per second. Best solution?\n",
    "\n",
    "A) Data Warehouse\n",
    "B) Lakehouse\n",
    "C) KQL Database + Event Streams\n",
    "D) Power BI dataset\n",
    "\n",
    "**Answer**: C (KQL + Event Streams)\n",
    "**Explanation**: KQL optimized for high-volume, time-series streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fea3b",
   "metadata": {},
   "source": [
    "# Part 11: Study Resources and Timeline\n",
    "\n",
    "## Learning Resources\n",
    "\n",
    "### Official Microsoft\n",
    "- **Microsoft Learn**: Free Fabric learning paths\n",
    "- **Exam Skills Outline**: Official blueprint\n",
    "- **Fabric Documentation**: docs.microsoft.com/fabric\n",
    "- **Virtual Training**: Instructor-led labs\n",
    "\n",
    "### Hands-on Practice\n",
    "- **Microsoft Learn Labs**: Free interactive exercises\n",
    "- **Fabric Trial**: 60-day free trial\n",
    "- **Practice Exams**: MeasureUp, ExamTopics\n",
    "- **YouTube**: Microsoft Fabric tutorials\n",
    "\n",
    "## 8-Week Study Plan (Intermediate)\n",
    "\n",
    "### Week 1-2: Fabric Fundamentals\n",
    "- Day 1-2: Workspace, capacity, licensing\n",
    "- Day 3-4: OneLake and storage concepts\n",
    "- Day 5-6: Hands-on workspace setup\n",
    "- Day 7: Review + practice\n",
    "\n",
    "### Week 3-4: Data Warehouse\n",
    "- Day 1-2: Warehouse fundamentals\n",
    "- Day 3-4: SQL and table design\n",
    "- Day 5-6: Loading and optimization\n",
    "- Day 7: Hands-on exercise\n",
    "\n",
    "### Week 5: Lakehouse\n",
    "- Day 1-2: Lakehouse concepts\n",
    "- Day 3-4: Delta format and operations\n",
    "- Day 5-6: Hands-on Lakehouse\n",
    "- Day 7: Review\n",
    "\n",
    "### Week 6: Integration and Analytics\n",
    "- Day 1-2: Pipelines and dataflows\n",
    "- Day 3-4: Semantic models and DAX\n",
    "- Day 5-6: Hands-on integration\n",
    "- Day 7: Review\n",
    "\n",
    "### Week 7: Advanced Topics\n",
    "- Day 1-2: Real-time analytics and KQL\n",
    "- Day 3-4: Notebooks and ML\n",
    "- Day 5-6: Governance and security\n",
    "- Day 7: Review\n",
    "\n",
    "### Week 8: Exam Preparation\n",
    "- Day 1-3: Take 3 practice exams\n",
    "- Day 4-5: Review weak areas\n",
    "- Day 6: Final review\n",
    "- Day 7: Exam day!\n",
    "\n",
    "## Success Criteria\n",
    "- Score 80%+ on practice exams\n",
    "- Complete all hands-on labs\n",
    "- Understand all storage options\n",
    "- Know when to use each tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35ba78",
   "metadata": {},
   "source": [
    "# Final Checklist Before Exam\n",
    "\n",
    "## Fabric Services âœ“\n",
    "- [ ] Understand workspace architecture\n",
    "- [ ] Know capacity sizing\n",
    "- [ ] Explain OneLake\n",
    "- [ ] Describe all Fabric workloads\n",
    "\n",
    "## Storage Options âœ“\n",
    "- [ ] Data Warehouse use cases\n",
    "- [ ] Lakehouse benefits\n",
    "- [ ] KQL Database for real-time\n",
    "- [ ] When to use each\n",
    "\n",
    "## Data Loading âœ“\n",
    "- [ ] Pipeline design\n",
    "- [ ] Dataflow transformations\n",
    "- [ ] Notebook data operations\n",
    "- [ ] Incremental loading patterns\n",
    "\n",
    "## Analytics âœ“\n",
    "- [ ] Semantic model types\n",
    "- [ ] DAX fundamentals\n",
    "- [ ] Star schema design\n",
    "- [ ] Relationship configuration\n",
    "\n",
    "## Reporting âœ“\n",
    "- [ ] Report design best practices\n",
    "- [ ] Visualization selection\n",
    "- [ ] Interactivity features\n",
    "- [ ] Performance optimization\n",
    "\n",
    "## Advanced âœ“\n",
    "- [ ] KQL query basics\n",
    "- [ ] Spark notebook operations\n",
    "- [ ] ML pipeline setup\n",
    "- [ ] Security and governance\n",
    "\n",
    "## Practice âœ“\n",
    "- [ ] Score 85%+ on practice exams\n",
    "- [ ] Complete 5+ hands-on projects\n",
    "- [ ] Know decision trees\n",
    "- [ ] Familiar with all UIs\n",
    "\n",
    "---\n",
    "\n",
    "# You're Ready for DP600! ðŸŽ¯\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Fabric = Unified cloud analytics platform\n",
    "- Choose storage: Warehouse (SQL), Lakehouse (Data), KQL (Real-time)\n",
    "- Orchestrate with Pipelines and Dataflows\n",
    "- Model with semantic models + DAX\n",
    "- Visualize with Power BI\n",
    "\n",
    "**Good Luck on Your DP600 Exam! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
